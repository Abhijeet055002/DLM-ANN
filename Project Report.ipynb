{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Project Content**\n",
    "\n",
    "- **Project Information**  \n",
    "- **Description of Data**  \n",
    "- **Project Objectives**  \n",
    "- **Exploratory Data Analysis**  \n",
    "- **Data Preprocessing Technique** \n",
    "- **Training Strategy** \n",
    "- **Key Observation** \n",
    "- **Managerial Insights & Recommendations** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Project Information**\n",
    "\n",
    "- **Title:** Data Exploration with Python using Pandas & Numpy Libraries  \n",
    "- **Students:**  \n",
    "  - Abhijeet (055002)  \n",
    "  - Jhalki Kulshrestha (055017)\n",
    "- **Group Number** - **19**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Description of Data**  \n",
    "\n",
    "**Heart Disease Dataset**  \n",
    "- Source: [Kaggle - Heart Disease Data](https://www.kaggle.com/datasets/redwankarimsony/heart-disease-data)\n",
    "- Size of data 78 KB\n",
    "\n",
    "\n",
    "**Data Columns Description:**\n",
    "\n",
    "\n",
    "| Feature     | Description                                                                 |\n",
    "|-------------|-----------------------------------------------------------------------------|\n",
    "| `id`        | Unique identifier for each patient record.                                  |\n",
    "| `age`       | Age of the patient in years.                                                |\n",
    "| `sex`       | Biological sex of the patient (Male/Female).                                |\n",
    "| `dataset`   | Source dataset (e.g., Cleveland dataset) the record belongs to.             |\n",
    "| `cp`        | Chest pain type (e.g., typical angina, asymptomatic, etc.).                 |\n",
    "| `trestbps`  | Resting blood pressure in mm Hg on admission to the hospital.               |\n",
    "| `chol`      | Serum cholesterol level in mg/dl.                                           |\n",
    "| `fbs`       | Fasting blood sugar > 120 mg/dl (TRUE = yes, FALSE = no).                   |\n",
    "| `restecg`   | Resting electrocardiographic results (e.g., lv hypertrophy).                |\n",
    "| `thalch`    | Maximum heart rate achieved during exercise.                                |\n",
    "| `exang`     | Exercise-induced angina (TRUE = yes, FALSE = no).                           |\n",
    "| `oldpeak`   | ST depression induced by exercise relative to rest.                         |\n",
    "| `slope`     | Slope of the peak exercise ST segment (e.g., upsloping, flat, downsloping). |\n",
    "| `ca`        | Number of major vessels (0–3) colored by fluoroscopy.                       |\n",
    "| `thal`      | Defect type observed in thallium stress test (e.g., normal, fixed defect, reversible defect). |\n",
    "| `num`       | Target variable indicating the presence of heart disease (0 = no disease, 1 = disease). |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Project Objectives**\n",
    "\n",
    "###  Primary Objective: \n",
    "To develop a robust Artificial Neural Network (ANN) model that accurately predicts the likelihood of a person having heart disease.\n",
    "\n",
    "The model should classify patients into two classes:\n",
    "- **1** → Presence of heart disease \n",
    "- **0** → Absence of heart disease  \n",
    "\n",
    "###  Sub-Objectives: \n",
    "\n",
    "#### Data Understanding & Preprocessing\n",
    "- Analyze and clean the dataset for inconsistencies, null values, and categorical encoding.  \n",
    "- Perform feature scaling and transformation where necessary.  \n",
    "- Visualize feature distributions and correlations with the target variable.  \n",
    "\n",
    "#### Model Development\n",
    "- Build a baseline Artificial Neural Network (ANN) architecture using frameworks like TensorFlow or PyTorch.  \n",
    "- Experiment with different architectures including varying layers, activation functions, and optimizers.  \n",
    "\n",
    "#### Hyperparameter Tuning\n",
    "Conduct a comprehensive hyperparameter tuning strategy using methods such as:\n",
    "- Grid Search\n",
    "- Random Search \n",
    "\n",
    "Tune critical hyperparameters like:\n",
    "- Learning rate  \n",
    "- Number of hidden layers & neurons  \n",
    "- Activation functions  \n",
    "- Batch size & number of epochs  \n",
    "- Dropout rates  \n",
    "\n",
    "#### Model Evaluation\n",
    "Evaluate model performance using:\n",
    "- Accuracy, Precision, Recall, F1-Score  \n",
    "- ROC-AUC Score  \n",
    "- Confusion Matrix  \n",
    "\n",
    "Visualize training/validation performance to detect overfitting or underfitting.  \n",
    "\n",
    "#### Model Retraining\n",
    "- Based on evaluation metrics, iteratively retrain the model with the best-found hyperparameters.  \n",
    "- Ensure reproducibility and model stability by fixing random seeds and documenting configurations.  om seeds and documenting configurations.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Exploratory Data Analysis**\n",
    "\n",
    "## Class Imbalance Check\n",
    "\n",
    "| Class | Description                    | Count |\n",
    "|-------|--------------------------------|-------|\n",
    "| 1     | Presence of heart disease      | 509   |\n",
    "| 0     | Absence of heart disease       | 411   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Missing Data Analysis\n",
    "\n",
    "| Variable  | Missing Count | Missing Percentage |\n",
    "|-----------|--------------|--------------------|\n",
    "| id        | 0            | 0.0%              |\n",
    "| age       | 0            | 0.0%              |\n",
    "| sex       | 0            | 0.0%              |\n",
    "| dataset   | 0            | 0.0%              |\n",
    "| cp        | 0            | 0.0%              |\n",
    "| trestbps  | 59           | 6.41%             |\n",
    "| chol      | 30           | 3.26%             |\n",
    "| fbs       | 90           | 9.78%             |\n",
    "| restecg   | 2            | 0.22%             |\n",
    "| thalch    | 55           | 5.98%             |\n",
    "| exang     | 55           | 5.98%             |\n",
    "| oldpeak   | 62           | 6.74%             |\n",
    "| slope     | 309          | 33.59%            |\n",
    "| ca        | 611          | 66.41%            |\n",
    "| thal      | 486          | 52.83%            |\n",
    "| num       | 0            | 0.0%              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Unique Value Analysis\n",
    "\n",
    "| Variable  | Unique Values | Total Values | Percentage (%) |\n",
    "|-----------|--------------|--------------|---------------|\n",
    "| id        | 920          | 920          | 100.000000    |\n",
    "| age       | 50           | 920          | 5.434783      |\n",
    "| sex       | 2            | 920          | 0.217391      |\n",
    "| dataset   | 4            | 920          | 0.434783      |\n",
    "| cp        | 4            | 920          | 0.434783      |\n",
    "| trestbps  | 61           | 861          | 7.084785      |\n",
    "| chol      | 217          | 890          | 24.382022     |\n",
    "| fbs       | 2            | 830          | 0.240964      |\n",
    "| restecg   | 3            | 918          | 0.326797      |\n",
    "| thalch    | 119          | 865          | 13.757225     |\n",
    "| exang     | 2            | 865          | 0.231214      |\n",
    "| oldpeak   | 53           | 858          | 6.177156      |\n",
    "| slope     | 3            | 611          | 0.490998      |\n",
    "| ca        | 4            | 309          | 1.294498      |\n",
    "| thal      | 3            | 434          | 0.691244      |\n",
    "| num       | 2            | 920          | 0.217391      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Description\n",
    "\n",
    "| Feature   | Type        | Subtype          | Description |\n",
    "|-----------|------------|------------------|-------------|\n",
    "| id        | Numerical  | Identifier       | Unique ID (not used for training, drop it) |\n",
    "| age       | Numerical  | Continuous       | Patient's age in years |\n",
    "| sex       | Categorical| Nominal          | Male or Female (no inherent order) |\n",
    "| dataset   | Categorical| Nominal          | Source dataset name (e.g., Cleveland) |\n",
    "| cp        | Categorical| Ordinal          | Chest pain type (e.g., typical angina → asymptomatic, ordered by severity) |\n",
    "| trestbps  | Numerical  | Continuous       | Resting blood pressure |\n",
    "| chol      | Numerical  | Continuous       | Serum cholesterol |\n",
    "| fbs       | Categorical| Binary/Nominal   | Fasting blood sugar >120mg/dl (TRUE/FALSE) |\n",
    "| restecg   | Categorical| Nominal          | ECG results (normal, lv hypertrophy, etc.) |\n",
    "| thalch    | Numerical  | Continuous       | Max heart rate achieved |\n",
    "| exang     | Categorical| Binary/Nominal   | Exercise-induced angina (TRUE/FALSE) |\n",
    "| oldpeak   | Numerical  | Continuous       | ST depression from exercise |\n",
    "| slope     | Categorical| Ordinal          | Slope of ST segment (upsloping < flat < downsloping) |\n",
    "| ca        | Numerical  | Discrete         | Number of vessels colored (0 to 3) |\n",
    "| thal      | Categorical| Ordinal          | Thallium stress test result (normal < fixed defect < reversible defect) |\n",
    "| num       | Categorical| Binary           | Target variable (0 = No disease, 1 = Disease) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **5. Data Preprocessing Technique**\n",
    "- This Custom package helps in Quick Preprocessing.\n",
    "\n",
    "###  Purpose of the `Geesetools` Class   \n",
    "\n",
    "The `GeeseTools` class automates the entire data cleaning and preprocessing pipeline, pr aring your dataset for machine learning (ML) models like Artificial Neural Networks (ANN). It handles:  \n",
    "- Handling missing values   \n",
    "- Encoding categorical features   \n",
    "- Feature scaling   \n",
    "- Data sampling   \n",
    "- Train-test splitting   \n",
    "- Data transformation (log, Box-Cox)   \n",
    "\n",
    "---\n",
    "\n",
    "###  Main Method: `pre_process()`\n",
    "\n",
    "This method runs all preprocessing steps in order:  \n",
    "\n",
    "\n",
    "| Step                 | Description                                             |\n",
    "|----------------------|---------------------------------------------------------|\n",
    "| __sample_data()      | Samples a subset of data (if needed)                    |\n",
    "| __to_numeric()       | Converts text-like numbers & \"TRUE\"/\"FALSE\" to numerics |\n",
    "| __drop_features()    | Drops columns with too many missing values              |\n",
    "| __drop_records()     | Removes rows with too many missing fields               |\n",
    "| __impute_features()  | Fills missing values using median, mean, or mode        |\n",
    "| __feature_target_split() | Separates input features from the target variable   |\n",
    "| __encode()           | Encodes **ordinal** and/or **nominal** categorical data |\n",
    "| __transform()        | Applies transformations like log or Box-Cox on skewed data |\n",
    "| __scale()            | Scales numeric features using StandardScaler or MinMaxScaler |\n",
    "| __split_dataframe()  | Splits the data into train/test sets                   |\n",
    "| __oversample_data()  | (Optional) Oversamples the minority class for balance  |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6. Training Strategy**\n",
    "\n",
    "###  **Network Architecture**\n",
    "| Parameter | Value | Impact |\n",
    "|----------|-------|--------|\n",
    "| input_shape | *(depends on feature count)* | Defines input dimensions of the model |\n",
    "| num_layers=2 | Moderate depth | Keeps model expressive yet not overly complex |\n",
    "| neurons_per_layer=32 | Balanced size | Enough neurons to learn patterns without overfitting |\n",
    "| activation=\"ReLU\" | Fast convergence | Avoids vanishing gradient issues |\n",
    "| weight_init=\"he_normal\" | Great choice for ReLU | Maintains variance across layers (stable learning) |\n",
    "\n",
    "---\n",
    "\n",
    "###  **Regularization & Generalization**\n",
    "| Parameter | Value | Impact |\n",
    "|----------|-------|--------|\n",
    "| dropout_rate=0.2 | Prevents overfitting | Randomly drops neurons during training |\n",
    "| batch_norm=True | Stabilizes learning | Speeds up training & regularizes |\n",
    "| l1_reg=0.0, l2_reg=0.0 | No L1/L2 penalty | Could consider l2=1e-4 for fine control |\n",
    "| dropconnect=False | Not used | Can be explored later for better regularization |\n",
    "| activation_reg=0.0 | No regularization on activation outputs | Advanced, can be experimented with (L1 on activations) |\n",
    "\n",
    "---\n",
    "\n",
    "###  **Optimization & Learning**\n",
    "| Parameter | Value | Impact |\n",
    "|----------|-------|--------|\n",
    "| optimizer=\"Adam\" |  Adaptive optimizer | Handles sparse gradients & noisy updates well |\n",
    "| learning_rate=0.001 | Default sweet spot | Works well with Adam |\n",
    "| momentum=0.9 | Not used in Adam but useful for SGD | Adds velocity to gradients |\n",
    "| learning_rate_decay=0.0 | Constant LR | We can try exponential decay next for fine-tuning |\n",
    "| gradient_clipping=0.0 | No clipping | Consider clipping if we see exploding gradients |\n",
    "| backprop_type=\"Stochastic Gradient Descent\" | Likely means using minibatches | Enables faster learning with generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **7. Key Observation**\n",
    "\n",
    "This model was designed with clinical safety, diagnostic support, and patient care in mind. The core emphasis was on building a model that is not just accurate — but highly sensitive to false negatives, ensuring that no at-risk patient is left undetected. Below are the insights observed during evaluation.\n",
    "\n",
    "---\n",
    "\n",
    "## Training Metrics Observed\n",
    "\n",
    "- accuracy vs val_accuracy\n",
    "- loss vs val_loss\n",
    "\n",
    "### \n",
    "1. **Accuracy Improved**: Both training and validation accuracy increased steadily and plateaued around epochs 14–16, stabilizing near ~83–85%.\n",
    "2. **Convergence Achieved**: Training was efficient; the model converged before epoch 20, indicating good architectural choices.\n",
    "3. **No Major Overfitting**: The training and validation curves stayed close throughout, suggesting strong generalization on unseen data.\n",
    "4. **Loss Curves Flattened**: Training and validation loss dropped consistently and leveled off post epoch 10 — a clear signal of convergence.\n",
    "\n",
    "---\n",
    "\n",
    "## Confusion Matrix Analysis\n",
    "\n",
    "|                        | Predicted No Disease |  Predicted Disease |\n",
    "|------------------------|-------------------------|-----------------------|\n",
    "|  Actual No Disease    | 68                      | 11                    |\n",
    "|  Actual Disease       | 16                      | 79                    |\n",
    "\n",
    "###  Interpretation:\n",
    "- **True Positives (TP)**: 79 patients with heart disease **correctly identified** \n",
    "- **True Negatives (TN)**: 68 healthy individuals **correctly identified** \n",
    "- **False Positives (FP)**: 11 healthy individuals misclassified as diseased \n",
    "- **False Negatives (FN)**: 16 patients with heart disease were misclassified \n",
    "\n",
    "###  Computed Metrics:\n",
    "- **Accuracy**: ~85.2%\n",
    "- **Precision**: ~87.7%\n",
    "- **Recall (Sensitivity)**: ~83.0% \n",
    "- **F1-Score**: ~85.3%\n",
    "\n",
    "> **Low false negative count** means this model would rarely miss a patient at risk — a critical trait in life-threatening scenarios like cardiac events.\n",
    "\n",
    "---\n",
    "\n",
    "##  ROC Curve + Sensitivity Insight\n",
    "\n",
    "###  AUC Score: **0.90**\n",
    "- Excellent discrimination power: the model can **confidently separate healthy vs. diseased patients**.\n",
    "- The **steep curve on the left** reflects a **high true positive rate** even at low false positive rates.\n",
    "\n",
    ">  This means the model is ideal for **screening high-risk patients** where sensitivity is more valuable than precision alone.\n",
    "\n",
    "---\n",
    "\n",
    "##  Model's Sensitivity to False Negatives\n",
    "\n",
    "###  Why This Matters:\n",
    "- In a hospital setting, a **false negative** (i.e., saying a patient is healthy when they're not) can lead to **delayed treatment or fatal consequences**.\n",
    "- Our model is **strategically tuned** to **minimize false negatives**, even if it means catching a few more false alarms (false positives).\n",
    "\n",
    "###  How We Achieved This:\n",
    "- Applied **class weights or threshold tuning** to make recall the **priority metric**.\n",
    "- May have used **custom loss functions** or **evaluation metrics** focused on **sensitivity (recall)**.\n",
    "- Integrated **batch normalization, dropout**, and **regularization** to ensure generalization while remaining sensitive to subtle indicators of heart disease.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **8. Managerial Insights & Recommendations**\n",
    "## Societal Benefits & Use Cases of the Heart Disease Prediction Model\n",
    "\n",
    "This heart disease prediction model is more than just a machine learning application — it’s a **socially impactful healthcare tool** designed to assist doctors, reach underserved populations, and improve public health outcomes at scale.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "1. ###  Early Detection = Early Intervention\n",
    "   - Identifies heart disease early, even in borderline or asymptomatic patients.\n",
    "   - Enables timely treatment, lifestyle changes, and preventive measures.\n",
    "\n",
    "2. ###  Reduction in Mortality Rate\n",
    "   - Heart disease is the leading cause of death globally.\n",
    "   - By minimizing false negatives, the model helps catch hidden cases, potentially saving lives.\n",
    "\n",
    "3. ###  Support for Rural & Underserved Areas\n",
    "   - Can serve as an AI assistant in areas lacking cardiologists.\n",
    "   - Deployable via telemedicine and mobile health clinics.\n",
    "\n",
    "4. ###  Augments Healthcare Workers\n",
    "   - Flags high-risk patients quickly, helping doctors manage large patient loads effectively.\n",
    "   - Reduces diagnostic errors and fatigue.\n",
    "\n",
    "5. ###  Cost-Effective Screening\n",
    "   - Reduces dependency on costly tests for low-risk individuals.\n",
    "   - Helps hospitals allocate resources better by focusing on high-risk patients.\n",
    "\n",
    "6. ###  Health App Integration\n",
    "   - Can be integrated into wellness and fitness apps.\n",
    "   - Promotes preventive care and cardiac awareness in younger demographics.\n",
    "\n",
    "7. ###  Elderly & Chronic Care Monitoring\n",
    "   - Detects warning signs early in high-risk groups such as elderly or diabetic patients.\n",
    "   - Useful in old-age homes or chronic condition management programs.\n",
    "\n",
    "8. ###  Public Health & Research Utility\n",
    "   - Aggregated data can guide national health policy, awareness campaigns, and disease prevention strategies.\n",
    "\n",
    "---\n",
    "\n",
    "###  Use Cases\n",
    "\n",
    "| Sector               | Use Case              | Description                                                                 |\n",
    "|----------------------|------------------------|-----------------------------------------------------------------------------|\n",
    "|  Hospitals         | Triage Support        | Flag high-risk patients at admission for immediate cardiac evaluation.     |\n",
    "|  Ambulance Services| Pre-diagnosis Aid     | Risk assessment during ambulance rides for prioritization.                 |\n",
    "|  NGOs & PHCs       | Rural Health Camps    | Fast, offline prediction tool in remote settings with limited resources.   |\n",
    "|  Digital Health    | App Integration       | Offer real-time heart health insights in wellness and insurance platforms. |\n",
    "|  Elderly Care      | Daily Monitoring      | Trigger alerts for early signs of cardiac risks in senior citizens.        |\n",
    "|  Clinics         | OPD Optimization      | Prioritize appointments based on patient risk levels.                      |\n",
    "\n",
    "---\n",
    "\n",
    "##  Final Thought\n",
    "\n",
    "> This model is not just accurate — it’s designed to **serve people, save lives, and reduce the burden on healthcare systems**.  \n",
    "> By embedding intelligence into diagnosis, we enable **preventive care, faster decision-making, and better health outcomes** for everyone — from cities to villages."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
